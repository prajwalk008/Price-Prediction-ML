{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Submission 2: Deep Learning Ensemble\n",
    "\n",
    "**Author:** Prajwal Kambale, Team Init to WinIt\n",
    "\n",
    "## Approach Summary: The \"Committee of Experts\"\n",
    "After initial experiments showed that simply combining text and image features into a single model did not yield significant improvements (indicating a feature redundancy problem), a more sophisticated ensembling strategy was adopted. \n",
    "\n",
    "This approach, which I call the \"Committee of Experts,\" treats the text and image data as separate domains requiring specialized models:\n",
    "1.  **The \"Text Expert\":** A LightGBM model trained on a rich set of engineered and TF-IDF features. It excels at understanding explicit details in the product description.\n",
    "2.  **The \"Image Expert\":** A fine-tuned EfficientNet model. This deep learning model was trained in a prior step to specialize in predicting price directly from visual cues.\n",
    "\n",
    "This notebook documents the final step: training the Text Expert on the full dataset, loading the pre-trained Image Expert, and blending their predictions to generate the final submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Applying Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"--- Building the Standalone Text Expert ---\")\n",
    "df_train = pd.read_feather('dataset/train_processed.feather')\n",
    "\n",
    "\n",
    "df_train['item_quantity'] = df_train['catalog_content'].str.lower().str.extract(r'(?:pack of|count|pk|set of|pack)\\s*:?\\s*(\\d+)').fillna(1).astype(int)\n",
    "\n",
    "\n",
    "brand_counts = df_train['brand'].value_counts()\n",
    "rare_brands = brand_counts[brand_counts < 10].index\n",
    "df_train['brand'] = df_train['brand'].replace(rare_brands, 'Other')\n",
    "\n",
    "\n",
    "text_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['item_quantity']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['brand']),\n",
    "        ('tfidf', TfidfVectorizer(max_features=15000, stop_words='english', ngram_range=(1, 2)), 'catalog_content')\n",
    "    ], \n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "text_model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Training the Text Expert model on the full dataset...\")\n",
    "text_preprocessor.fit(df_train)\n",
    "X_train_transformed = text_preprocessor.transform(df_train)\n",
    "text_model.fit(X_train_transformed, df_train['log_price'])\n",
    "print(\"Text Expert is trained and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"--- Starting Final Submission Generation ---\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class FineTuningVisionModel(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet_b0', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.model.reset_classifier(num_classes=1)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "image_model = FineTuningVisionModel()\n",
    "image_model.load_state_dict(torch.load('best_vision_model.pth'))\n",
    "image_model.to(device)\n",
    "image_model.eval()\n",
    "print(\"Image Expert loaded successfully.\")\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('dataset/test.csv')\n",
    "df_test['item_quantity'] = df_test['catalog_content'].str.lower().str.extract(r'(?:pack of|count|pk|set of|pack)\\s*:?\\s*(\\d+)').fillna(1).astype(int)\n",
    "def extract_brand_fast(text):\n",
    "    match = re.search(r'^Item Name:\\s*(.+?)(?:,|$)', str(text))\n",
    "    return match.group(1).strip() if match else \"Unknown\"\n",
    "df_test['brand'] = df_test['catalog_content'].progress_apply(extract_brand_fast)\n",
    "print(\"Test data prepared.\")\n",
    "\n",
    "\n",
    "print(\"\\nGetting predictions from the Text Expert...\")\n",
    "X_test_text_transformed = text_preprocessor.transform(df_test)\n",
    "log_preds_text = text_model.predict(X_test_text_transformed)\n",
    "preds_text = np.expm1(log_preds_text)\n",
    "\n",
    "\n",
    "print(\"Getting predictions from the Image Expert (this will take a while)...\")\n",
    "class ImagePredictionDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df, self.image_dir, self.transform = df, image_dir, transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(image_dir, f\"{row['sample_id']}.jpg\")\n",
    "        try: image = Image.open(image_path).convert('RGB')\n",
    "        except FileNotFoundError: image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "image_transforms = timm.data.create_transform(**timm.data.resolve_model_data_config(image_model.model), is_training=False)\n",
    "test_image_dataset = ImagePredictionDataset(df=df_test, image_dir='images/', transform=image_transforms)\n",
    "test_loader = DataLoader(test_image_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "all_image_preds = []\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loader, desc=\"Image Expert Predicting on Test Set\")\n",
    "    for images in loop:\n",
    "        images = images.to(device)\n",
    "        log_preds = image_model(images).squeeze()\n",
    "        all_image_preds.append(log_preds.cpu().numpy())\n",
    "\n",
    "log_preds_image = np.concatenate(all_image_preds)\n",
    "preds_image = np.expm1(log_preds_image)\n",
    "\n",
    "\n",
    "print(\"\\nBlending predictions and saving submission file...\")\n",
    "blend_weight_text = 0.90\n",
    "blend_weight_image = 0.10\n",
    "blended_preds = (preds_text * blend_weight_text) + (preds_image * blend_weight_image)\n",
    "blended_preds[blended_preds < 0] = 0\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_id': df_test['sample_id'],\n",
    "    'price': blended_preds\n",
    "})\n",
    "submission_df.to_csv('test_result2.csv', index=False)\n",
    "\n",
    "print(\"\\n--- DL ENSEMBLE SUBMISSION FILE CREATED SUCCESSFULLY! ---\")\n",
    "print(\"File 'test_result2.csv' is ready for submission.\")\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
