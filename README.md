\documentclass[11pt, a4paper]{article}

% --- UNIVERSAL PREAMBLE BLOCK ---
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{fontspec}

\usepackage[english, bidi=basic, provide=*]{babel}
\babelprovide[import, onchar=ids fonts]{english}

% Set default/Latin font to Sans Serif in the main (rm) slot
\babelfont{rm}{Noto Sans}
% --- END UNIVERSAL PREAMBLE BLOCK ---

% Additional packages needed for this document
\usepackage{amsmath} % For math environments like $$...$$
\usepackage{booktabs} % For professional tables (\toprule, \midrule, \bottomrule)
\usepackage{hyperref} % For hyperlinks (load last)

% Document Metadata
\title{Grocery Price Predictor - Amazon ML Challenge Approach}
\author{[Your Name/Team Name]} % Replace with your name/team name
\date{\today}

\begin{document}

\maketitle

\section{Project Goal}
This project aims to \textbf{predict the price of grocery items} based on their \textbf{product description and image}, as part of the \textbf{Amazon ML Challenge 2025}.
The challenge involves analyzing complex relationships between product attributes (brand, specifications, quantity) and their corresponding market price.

\hrulefill % Represents ---

\section{Approach Overview: \textit{The "Committee of Experts" Ensemble}}
Initial explorations revealed the limitations of using a single model or simple feature combinations for this \textbf{multimodal problem} (text + image).
A key insight was that the dataset consisted primarily of grocery items, where price drivers vary significantly across categories (e.g., coffee vs. sauces).

Therefore, a more sophisticated \textbf{ensemble strategy}, termed the \textbf{"Committee of Experts"}, was adopted.
This approach leverages specialized models for each data modality:
\begin{itemize}
    \item \textbf{The "Text Expert"}: A \textbf{Gradient Boosting model (LightGBM)} trained on carefully engineered features derived from the product description and category information.
    \item \textbf{The "Image Expert"}: A \textbf{fine-tuned Convolutional Neural Network (EfficientNet-B0)} specifically trained to predict \texttt{log\_price} directly from product images, capturing visual cues related to value.
\end{itemize}
The final price prediction is generated by \textbf{blending the outputs} of these two expert models using a weighted average, combining their distinct strengths.

\hrulefill % Represents ---

\section{Data}
The dataset provided contains:

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Column Name} & \textbf{Description} \\
\midrule
\texttt{sample\_id} & Unique identifier \\
\texttt{catalog\_content} & Text description including title, details, and Item Pack Quantity (IPQ) \\
\texttt{image\_link} & URL to the product image \\
\texttt{price} & Target variable (available only in the training set) \\
\bottomrule
\end{tabular}
\end{center}

\hrulefill % Represents ---

\section{Methodology}

\subsection{Data Preparation and Categorization}
\begin{itemize}
    \item \textbf{Log Transformation} The target variable \texttt{price} exhibited a strong right skew.
    A \texttt{log1p} transformation (\texttt{log\_price = np.log1p(price)}) was applied to stabilize the target distribution.
    Models were trained to predict \texttt{log\_price}.

    \item \textbf{Intelligent Categorization} Recognizing the grocery-specific nature, an initial \textbf{rule-based system} followed by a \textbf{data-driven keyword scoring engine} was developed (using \textbf{TF-IDF} on the "Other" category) to classify products into meaningful categories such as:
    \begin{itemize}
        \item \textit{Coffee \& Tea}
        \item \textit{Chocolates \& Candy}
        \item \textit{Sauces}
    \end{itemize}
    This approach significantly improved data understanding compared to simple rule-based methods.
\end{itemize}

\subsection{The "Text Expert" (LightGBM)}
This model focuses on extracting signals from the \texttt{catalog\_content}.

\subsubsection{Feature Engineering}
\begin{itemize}
    \item \textbf{Item Pack Quantity (IPQ):} Extracted using regex — quantity is a primary price driver.
    \item \textbf{Brand:} Extracted using NLP (\texttt{spaCy} for NER) during EDA and refined with regex for the final pipeline.
    Rare brands were grouped under \texttt{"Other"} to reduce noise.
    \item \textbf{Category:} The intelligently derived category was used as a crucial categorical feature.
    \item \textbf{Text Representation:} TF-IDF (Term Frequency–Inverse Document Frequency) with n-grams (1,2) converted raw text into a high-dimensional sparse matrix capturing important keywords and phrases.
\end{itemize}

\subsubsection{Modeling}
A \textbf{LightGBM regressor} was trained on the combination of engineered numerical/categorical features and TF-IDF features.

\subsection{The "Image Expert" (Fine-Tuned EfficientNet)}
This model captures visual price signals that text-based models might miss.

\subsubsection{Rationale}
Visual cues like \textbf{packaging quality, branding, product appearance}, and \textbf{bulk presentation} influence perceived value.

\subsubsection{Fine-Tuning}
\begin{itemize}
    \item Used \textbf{EfficientNet-B0} pre-trained on \textbf{ImageNet}.
    \item The final classification layer was replaced with a \textbf{single regression neuron} to output \texttt{log\_price}.
    \item Model trained directly on product images with \texttt{log\_price} as the target.
\end{itemize}

\subsubsection{Checkpointing}
The best model (based on validation loss) was saved after each epoch to prevent overfitting.
Final saved model: \texttt{best\_vision\_model.pth}

\subsection{Ensembling Strategy}
Predictions from both expert models were combined for the final estimate.

\subsubsection{Steps}
\begin{enumerate}
    \item \textbf{Prediction Generation:} Both the \textbf{Text Expert (LightGBM)} and \textbf{Image Expert (EfficientNet)} predict \texttt{log\_price} for the test set.

    \item \textbf{Inverse Transformation:} Convert predictions back to original scale using:
    \begin{verbatim}
price = np.expm1(log_price)
    \end{verbatim}

    \item \textbf{Weighted Blending}

The final price was calculated as a \textbf{weighted average} of the two predictions:
$$
\text{Final Price} = (\text{Text\_Price} \times W_{\text{text}}) + (\text{Image\_Price} \times W_{\text{image}})
$$
Experimentation on the validation set showed that a \textbf{higher weight for the text model} yielded the best results,
with the optimal blend being approximately \textbf{90\% Text Expert / 10\% Image Expert}.
\end{enumerate}

\hrulefill % Represents ---

\section{Results}
The final ensemble model, combining the strengths of detailed text analysis and specialized visual understanding,
achieved a \textbf{SMAPE score of approximately 53.02\%} on the validation set.

This score reflects the performance of the blended \textbf{"Committee of Experts"} approach.

\begin{quote}
\textbf{Self-correction:} While the feature-engineered model alone achieved \textasciitilde{}51\%,
the ensemble score with the DL component was \textasciitilde{}53\%.
This README accurately reflects the score achieved by the described ensemble method.
\end{quote}

\hrulefill % Represents ---

\section{Technology Stack}
\begin{itemize}
    \item \textbf{Python 3}
    \item \texttt{pandas}, \texttt{numpy}
    \item \texttt{scikit-learn} — for preprocessing, TF-IDF, and model evaluation
    \item \texttt{LightGBM} — for the Text Expert model
    \item \texttt{PyTorch} — for the Image Expert model (training and inference)
    \item \texttt{timm} — PyTorch Image Models library for EfficientNet
    \item \texttt{transformers} — Hugging Face library, used for initial zero-shot experiments
    \item \texttt{Pillow} — for image loading
    \item \texttt{joblib} — for saving/loading models
    \item \texttt{tqdm} — for progress bars
\end{itemize}

\hrulefill % Represents ---

\section{Running the Code}
The primary code demonstrating the final ensemble approach is in \texttt{final\_dl\_training\_notebook.ipynb}.
To generate the submission file \texttt{test\_result2.csv}, follow these steps:
\begin{enumerate}
    \item \textbf{Install dependencies} Ensure all dependencies from \texttt{requirements.txt} are installed:
    \begin{verbatim}
pip install -r requirements.txt
    \end{verbatim}

    \item \textbf{Place model file} Place the trained image model \texttt{best\_vision\_model.pth} in the project's root directory.

    \item \textbf{Place data files} Place the necessary data files (\texttt{train\_processed.feather}, \texttt{test.csv}) in a \texttt{dataset/} subfolder.

    \item \textbf{Ensure image folder} Ensure the \texttt{images/} folder containing all product images is present.

    \item \textbf{Run the notebook} Run the cells in \texttt{final\_dl\_training\_notebook.ipynb} sequentially. The final cell will generate \texttt{test\_result2.csv}.
\end{enumerate}

\end{document}
